import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import euclidean_distances
import json
import os


def detect_chorus_auto(audio_path, sr=22050, n_bins=72, hop_length=512, m=None, visualize=True):
    """è‡ªåŠ¨è‡ªé€‚åº”è°±èšç±»å‰¯æ­Œæ£€æµ‹"""
    print(f"ğŸ§ åŠ è½½éŸ³é¢‘ä¸­ï¼š{audio_path}")
    y, sr = librosa.load(audio_path, sr=sr, mono=True)

    # ğŸ¥ Beat tracking
    tempo, beats = librosa.beat.beat_track(y=y, sr=sr, hop_length=hop_length)
    tempo = float(np.atleast_1d(tempo)[0])
    beat_times = librosa.frames_to_time(beats, sr=sr, hop_length=hop_length)
    n_beats = len(beats)
    print(f"âœ… æ£€æµ‹åˆ° {n_beats} ä¸ªèŠ‚æ‹, tempo={tempo:.1f} BPM")

    if n_beats < 8:
        raise ValueError("èŠ‚æ‹å¤ªå°‘ï¼Œæ— æ³•åˆ†æï¼Œè¯·å°è¯•å¦ä¸€é¦–æ­Œæ›²ã€‚")

    # è‡ªåŠ¨é€‰æ‹©è°±èšç±»ç»´åº¦
    if m is None:
        m = min(6, max(3, n_beats // 100))
    print(f"ğŸ“Š è‡ªåŠ¨é€‰æ‹©èšç±»å±‚æ¬¡æ•° m={m}")

    # ğŸ¼ ç‰¹å¾æå–
    C = np.abs(librosa.cqt(y, sr=sr, hop_length=hop_length, n_bins=n_bins))
    C_sync = librosa.util.sync(C, beats, aggregate=np.mean).T

    M = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)
    M_sync = librosa.util.sync(M, beats, aggregate=np.mean).T

    rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=hop_length)[0]
    rms_sync = librosa.util.sync(rms, beats, aggregate=np.mean)

    # ğŸ“ˆ é«˜æ–¯ç›¸ä¼¼åº¦
    def gaussian_affinity(X, k=8):
        dist = euclidean_distances(X, X)
        sigma = np.mean(np.sort(dist, axis=1)[:, k])
        return np.exp(-dist**2 / (2 * sigma**2 + 1e-8))

    S_rep = gaussian_affinity(C_sync, k=8)
    S_loc = gaussian_affinity(M_sync, k=8)
    n = S_rep.shape[0]

    # ğŸ” Recurrence matrix (Eq.1)
    k = 8
    knn = np.argsort(euclidean_distances(C_sync, C_sync), axis=1)[:, 1:k+1]
    R = np.zeros((n, n))
    for i in range(n):
        for j in knn[i]:
            if i in knn[j]:
                R[i, j] = 1
    R = np.maximum(R, R.T)

    # å¹³æ»‘
    w = 3
    R_prime = np.zeros_like(R)
    for i in range(n):
        for j in range(n):
            votes = [R[i+t, j+t] for t in range(-w, w+1)
                     if 0 <= i+t < n and 0 <= j+t < n]
            R_prime[i, j] = np.round(np.mean(votes))

    # åºåˆ—è¿æ¥ + åŠ æƒ
    Delta = np.eye(n, k=1) + np.eye(n, k=-1)
    dR = np.sum(R_prime, axis=1)
    dD = np.sum(Delta, axis=1)
    mu = np.dot(dD, dR + dD) / (np.sum((dR + dD)**2) + 1e-8)
    A = mu * (R_prime * S_rep) + (1 - mu) * (Delta * S_loc)

    # æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ
    D = np.diag(np.sum(A, axis=1))
    D_inv_sqrt = np.diag(1.0 / np.sqrt(np.sum(A, axis=1) + 1e-8))
    L = np.eye(n) - D_inv_sqrt @ A @ D_inv_sqrt
    L += np.eye(n) * 1e-6

    # è°±åˆ†è§£
    eigvals, eigvecs = np.linalg.eigh(L)
    eigvecs = eigvecs[:, :m]
    Y = eigvecs / (np.linalg.norm(eigvecs, axis=1, keepdims=True) + 1e-8)
    labels = KMeans(n_clusters=m, n_init=10, random_state=42).fit_predict(Y)

    # æ‰¾è¾¹ç•Œ
    boundaries = np.where(np.diff(labels) != 0)[0]
    boundary_times = beat_times[boundaries]

    # ğŸ” è®¡ç®—æ¯æ®µå¾—åˆ†ï¼ˆé‡å¤åº¦ + èƒ½é‡ï¼‰
    scores = []
    for k_label in set(labels):
        idx = np.where(labels == k_label)[0]
        submat = R_prime[np.ix_(idx, idx)]
        repeat_score = np.sum(submat)
        energy_score = np.mean(rms_sync[idx])
        scores.append(repeat_score * 0.7 + energy_score * 0.3)

    chorus_label = np.argmax(scores)
    chorus_start_idx = np.where(labels == chorus_label)[0][0]
    chorus_start_time = beat_times[chorus_start_idx]

    # ğŸ§  è‡ªåŠ¨ä¿®æ­£ï¼šé¿å…å‰å¥è¯¯åˆ¤
    if chorus_start_time < 15:
        mid = len(beat_times)//3
        chorus_start_time = float(np.median(beat_times[mid:mid*2]))
        print(f"âš ï¸ å‰¯æ­Œè¿‡æ—©ï¼Œè‡ªåŠ¨ä¿®æ­£åˆ°ä¸­æ®µ {chorus_start_time:.2f} ç§’")

    print(f"ğŸµ æœ€ç»ˆå‰¯æ­Œèµ·ç‚¹ â‰ˆ {chorus_start_time:.2f} ç§’")

    # ä¿å­˜ç»“æœ
    out_path = os.path.splitext(audio_path)[0] + "_chorus.json"
    data = {
        "file": os.path.basename(audio_path),
        "chorus_start_sec": float(chorus_start_time),
        "tempo": float(tempo),
        "segments": int(m)
    }
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {out_path}")

    # å¯è§†åŒ–
    if visualize:
        fig, ax = plt.subplots(1, 3, figsize=(15, 4))
        librosa.display.specshow(R_prime, x_axis='time', y_axis='time', ax=ax[0])
        ax[0].set_title("Recurrence matrix Râ€²")

        ax[1].scatter(range(len(labels)), labels, c=labels, cmap='tab10', s=20)
        ax[1].set_title("Spectral clustering structure")
        ax[1].set_xlabel("Beat index")
        ax[1].set_ylabel("Segment label")

        min_len = min(len(beat_times), len(rms_sync))
        ax[2].plot(beat_times[:min_len], rms_sync[:min_len], color='gray')
        ax[2].axvline(chorus_start_time, color='r', linestyle='--', label='Chorus start')
        ax[2].set_title("RMS Energy vs Time")
        ax[2].set_xlabel("Time (s)")
        ax[2].legend()

        plt.tight_layout()
        plt.show()

    return chorus_start_time, boundary_times, labels


# ğŸ§ª ç¤ºä¾‹è°ƒç”¨
if __name__ == "__main__":
    chorus_time, boundaries, labels = detect_chorus_auto(
        r"C:\Users\20281\Desktop\music\æè£æµ© - å¹´å°‘æœ‰ä¸º.mp3",
        visualize=True
    )
    print(f"\nğŸ¯ å‰¯æ­Œèµ·ç‚¹ â‰ˆ {chorus_time:.2f} ç§’")
